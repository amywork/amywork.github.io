---
layout: post
title: "Thread Programming"
author: "Amy"
---

<br>
# ê´€ë ¨ ì•„í‹°í´
- [Concurrency Programming Guide](https://www.objc.io/issues/2-concurrency/concurrency-apis-and-pitfalls/)
- [Low Level Concurrency APIs](https://www.objc.io/issues/2-concurrency/low-level-concurrency-apis/)
- [instruments / CPU Usage](https://help.apple.com/instruments/mac/current/)
- [Common Background Practices](https://www.objc.io/issues/2-concurrency/common-background-practices/)
- [Apple Document](https://developer.apple.com/library/archive/documentation/Cocoa/Conceptual/Multithreading/AboutThreads/AboutThreads.html#//apple_ref/doc/uid/10000057i-CH6-SW3)


<br>
<br>

# Concurrency API 
- `pthread` and `NSThread` // ìŠ¤ë ˆë“œë¥¼ ì§ì ‘ ë§Œë“œëŠ” ê²ƒì€ ë¹„ê¶Œì¥ (problem of too many threads being created)
- `Grand Central Dispatch`, `NSOperationQueue` // queue-based concurrency APIs
- `NSRunLoop`

<br>
<br>

# Threading Programming

âœ“ Threads are subunits of processes, which can be scheduled independently by the operating system scheduler.
- ìŠ¤ë ˆë“œëŠ” í”„ë¡œì„¸ìŠ¤ì˜ ì„œë¸Œ ìœ ë‹›ì´ê³ , OS ìŠ¤ì¼€ì¤„ëŸ¬ì— ì˜í•´ ë…ë¦½ì ìœ¼ë¡œ ìŠ¤ì¼€ì¤„ ë  ìˆ˜ ìˆë‹¤.

âœ“ Virtually all concurrency APIs are built on top of threads under the hood â€“ thatâ€™s true for both Grand Central Dispatch and operation queues.
- ëª¨ë“  concurrency API(GCD, Operation Queues) ë“¤ì€ ìŠ¤ë ˆë“œ ìœ„ì—ì„œ ì§€ì–´ì§„ë‹¤.

âœ“ The term thread is used to refer to a separate path of execution for code.
- ìŠ¤ë ˆë“œë€, ì‹¤í–‰í•˜ëŠ” ì½”ë“œë“¤ì˜ ë¶„ë¦¬ëœ ê¸¸ (1ì•± NìŠ¤ë ˆë“œ.. ì‹¤íƒ€ë˜ ê°™ì€ ê²ƒ.)

âœ“ The term process is used to refer to a running executable, which can encompass multiple threads.
- í”„ë¡œì„¸ìŠ¤ë€, ë©€í‹° ìŠ¤ë ˆë“œë¥¼ ì•„ìš¸ëŸ¬ì„œ ì‹¤í–‰ë˜ëŠ” ì½”ë“œ. (1ì•± 1í”„ë¡œì„¸ìŠ¤)

âœ“ The term task is used to refer to the abstract concept of work that needs to be performed.
- í…ŒìŠ¤í¬ë€, ì‹¤í–‰í•´ì•¼ í•˜ëŠ” ì¼ ë¬¶ìŒì•  ëŒ€í•œ ì¶”ìƒì ì¸ ë‹¨ìœ„

âœ“ From a technical standpoint, a thread is a combination of the kernel-level and application-level data structures needed to manage the execution of code. 
- ì½”ë“œ ì‹¤í–‰ì„ ê´€ë¦¬í•˜ê¸° ìœ„í•œ **ì»¤ë„ ë ˆë²¨**ê³¼ **ì–´í”Œë¦¬ì¼€ì´ì…˜ ë ˆë²¨**ì˜ ë°ì´í„° êµ¬ì¡° ì¡°í•©

âœ“ The kernel-level structures coordinate the dispatching of events to the thread and the preemptive scheduling of the thread on one of the available cores.
- **ì»¤ë„ ë ˆë²¨**ì—ì„œëŠ” **ì´ë²¤íŠ¸ë¥¼ ìŠ¤ë ˆë“œë¡œ ë””ìŠ¤íŒ¨ì¹˜** í•˜ëŠ” ê²ƒì„ ì¡°ì •í•˜ê³ , **ì‚¬ìš© ê°€ëŠ¥í•œ ì½”ì–´(CPU)ì—ë‹¤ê°€ ìŠ¤ì¼€ì¤„ë§**ì„ í•˜ê²Œ ëœë‹¤.

âœ“ The application-level structures include the call stack for storing function calls and the structures the application needs to manage and manipulate the threadâ€™s attributes and state.
- **ì–´í”Œë¦¬ì¼€ì´ì…˜ ë ˆë²¨**ì—ì„œëŠ” **í•¨ìˆ˜ ì½œì„ ìœ„í•œ stack ë° ìŠ¤ë ˆë“œì˜ ì†ì„±ê³¼ ìƒíƒœë¥¼ ê´€ë¦¬**í•œë‹¤.

âœ“ After starting a thread, the thread runs in one of three main states: running, ready, or blocked. If a thread is not currently running, it is either blocked and waiting for input or it is ready to run but not scheduled to do so yet. The thread continues moving back and forth among these states until it finally exits and moves to the terminated state.
- ìŠ¤ë ˆë“œì˜ ìƒíƒœëŠ” **running, ready, blocked 3ê°œ ì¤‘ì— í•˜ë‚˜**ì´ë‹¤. ì´ ìƒíƒœë¥¼ ì™”ë‹¤ ê°”ë‹¤ í•˜ë©´ì„œ ê³„ì†ë˜ë‹¤ê°€ ì¢…ë£Œëœë‹¤.

âœ“ When you create a new thread, you must specify an entry-point function. Because threads are relatively expensive to create in terms of memory and time, it is therefore recommended that your entry point function do a significant amount of work or set up a run loop to allow for recurring work to be performed.
- ìŠ¤ë ˆë“œë¥¼ ë§Œë“¤ ë•Œ `entry-point function` ì„ ì§€ì •í•´ì£¼ì–´ì•¼ í•œë‹¤. ê·¸ëŸ°ë° ìŠ¤ë ˆë“œë¥¼ ë§Œë“œëŠ” ì‘ì—…ì€ ê¾€ë‚˜ ë¹„ì‹¼ ì‘ì—…ì´ê¸° ë•Œë¬¸ì—, ì‹œì‘ì ì—ì„œ ë§ì€ ì–‘ì˜ ì¼ì„ í•˜ê¸°ë¥¼ ê¶Œì¥í•œë‹¤.

âœ“ Because threads in a single application share the same memory space, they have access to all of the same data structures. If two threads try to manipulate the same data structure at the same time, one thread might overwrite anotherâ€™s changes in a way that corrupts the resulting data structure.
- ë©”ëª¨ë¦¬ëŠ” ì‰ì–´ë˜ê¸° ë•Œë¬¸ì—, ì—¬ëŸ¬ ìŠ¤ë ˆë“œì—ì„œ ë™ì‹œì— ê°™ì€ ë°ì´í„°ë¥¼ get í•˜ê±°ë‚˜ set í•˜ë ¤ê³  í•˜ëŠ” **Racing Conditionì„ ì£¼ì˜**í•˜ì.

âœ“ Multiple threads can be executed at the same time on a single CPU core (or at least perceived as at the same time). The operating system assigns small slices of computing time to each thread.
- ì—¬ëŸ¬ê°œì˜ ìŠ¤ë ˆë“œê°€ ë™ì‹œì— í•˜ë‚˜ì˜ CPUì—ì„œ ì‘ë™ ê°€ëŠ¥ (OSê°€ ê° ìŠ¤ë ˆë“œë§ˆë‹¤ ì—°ì‚° ì‹œê°„ì„ ìª¼ê°œ ì¤Œ)

## Cost
âœ“ Threads donâ€™t come for free. Each thread ties up memory and kernel resources.
âœ“ The minimum allowed **stack size for secondary threads is 16 KB** and the stack size must be a multiple of 4 KB. The space for this memory is set aside in your process space at thread creation time, but the actual pages associated with that memory are not created until they are needed.
- ìŠ¤ë ˆë“œ ìƒì„±ì€ ê³µì§œê°€ ì•„ë‹ˆë‹¤. ë©”ëª¨ë¦¬ì™€ ì»¤ë„ ë¦¬ì†ŒìŠ¤ë¼ëŠ” ë¹„ìš©ì´ ë“ ë‹¤. 

<br>
<br>

# Run Loops

âœ“ A run loop is a piece of infrastructure used to manage events arriving asynchronously on a thread
- ëŸ°ëŸ¬í‘¸ëŠ” ìŠ¤ë ˆë“œì— ë„ì°©í•˜ëŠ” ì´ë²¤íŠ¸ë“¤ì„ ë¹„ë™ê¸°ë¡œ ì²˜ë¦¬í•˜ê¸° ìœ„í•œ í•˜ë¶€ êµ¬ì¡°ì´ë‹¤.

âœ“ As events arrive, the system wakes up the thread and dispatches the events to the run loop, which then dispatches them to the handlers you specify. If no events are present and ready to be handled, the run loop puts the thread to sleep.
- ì´ë²¤íŠ¸ê°€ ë„ì°©í•˜ë©´ ìŠ¤ë ˆë“œë¥¼ ê¹¨ì›Œì„œ ì´ë²¤íŠ¸ë¥¼ ëŸ°ë£¨í”„ì—ë‹¤ê°€ dispatch í•´ì£¼ê³ , ìµœì¢…ì ìœ¼ë¡œ í•¸ë“¤ëŸ¬ì— dispatch ëœë‹¤. ì•„ë¬´ëŸ° ì´ë²¤íŠ¸ê°€ ì—†ë‹¤ë©´ ëŸ°ë£¨í”„ëŠ” ìŠ¤ë ˆë“œë¥¼ ì¬ìš´ë‹¤.

âœ“ Because a run loop puts its thread to sleep when there is nothing to do, it eliminates the need for polling, which wastes CPU cycles and prevents the processor itself from sleeping and saving power.
- ëŸ°ë£¨í”„ëŠ” ìŠ¤ë ˆë“œë¥¼ ì ì¬ì› ë‹¤ ê¹¨ì› ë‹¤ í•˜ê¸° ë•Œë¬¸ì—, CPU ì‚¬ì´í´ì„ ì†Œëª¨í•˜ëŠ” polling ì˜ ë¹„íš¨ìœ¨ì„±ì„ ì—†ì• ì¤€ë‹¤.

ğŸ™‰ Polling ë°©ì‹?
- ì¹œêµ¬ë¥¼ ê¸°ë‹¤ë¦°ë‹¤ê³  ì¹˜ì. Polling ë°©ì‹ì´ë¼ë©´, ì¹œêµ¬ê°€ ì˜¬ ë•Œê¹Œì§€ ì•„ë¬´ê²ƒë„ í•˜ì§€ ì•Šê³  ê¸°ë‹¤ë¦¬ëŠ” ê²ƒ. Interrupt ë°©ì‹ ì´ë¼ë©´, ì¹œêµ¬ê°€ ì˜¬ ë–„ ê¹Œì§€ ì˜í™”ë³´ê³  ë°¥ë¨¹ê³  í•˜ë‹¤ê°€ ì „í™”ê°€ ì˜¤ë©´ ê·¸ ë–„ ë§ˆì¤‘ ë‚˜ê°€ëŠ” ê²ƒ.

âœ“ To configure a run loop, all you have to do is launch your thread, get a reference to the run loop object, install your event handlers, and tell the run loop to run. The infrastructure provided by OS X handles the configuration of the main threadâ€™s run loop for you automatically. If you plan to create long-lived secondary threads, however, you must configure the run loop for those threads yourself.
- ëŸ°ë£¨í”„ë¥¼ ë§Œë“¤ë ¤ë©´, ìŠ¤ë ˆë“œë¥¼ ì‹¤í–‰ ì‹œí‚¨ ë’¤ ëŸ°ë£¨í”„ ê°ì²´ì— ë ˆí¼ëŸ°ìŠ¤ í•´ì£¼ê³  ëŸ°ë£¨í”„ë¥¼ ë™ì‘ì‹œí‚¤ë©´ ëœë‹¤. 


### RunLoop Mode


âœ“ A run loop mode is a collection of input sources and timers to be monitored and a collection of run loop observers to be notified. Each time you run your run loop, you specify (either explicitly or implicitly) a particular â€œmodeâ€ in which to run. During that pass of the run loop, only sources associated with that mode are monitored and allowed to deliver their events.
- ëª¨ë“œì— ì§€ì •í•´ë‘” ì¸í’‹ ì†ŒìŠ¤ / íƒ€ì´ë¨¸ / ì˜µì €ë²„ë§Œ ëª¨ë‹ˆí„°ë§ í•˜ê³  ì´ë²¤íŠ¸ë¥¼ ë”œë¦¬ë²„ í•˜ê² ë‹¤ëŠ” ì˜ë¯¸


### ìŠ¤í¬ë¡¤ ë  ë–„ì˜ ëŸ°ë£¨í”„ ëª¨ë“œ (íƒ€ì´ë¨¸ ê´€ë ¨ ì´ìŠˆ)
âœ“ A typical example of this is scrolling on iOS. While youâ€™re scrolling, the run loop is not running in its default mode, and therefore, itâ€™s not going to react to, for example, a timer you have scheduled before. Once scrolling stops, the run loop returns to the default mode and the events which have been queued up are executed. If you want a timer to fire during scrolling, you need to add it to the run loop in the NSRunLoopCommonModes mode.
- ìŠ¤í¬ë¡¤ í•  ë•Œ ëŸ°ë£¨í”„ê°€ default modeì— ìˆì§€ ì•Šë‹¤. ë–„ë¬¸ì— íƒ€ì´ë¨¸ì— ë°˜ì‘í•˜ì§€ ì•Šì„ ê²ƒì´ë‹¤.
- ìŠ¤í¬ë¡¤ì´ ë©ˆì¶”ë©´, ëŸ°ë£¨í”„ëŠ” default modeë¡œ ëŒì•„ì˜¤ê³ , íì‰ëœ ì´ë²¤íŠ¸ë“¤ì„ ì²˜ë¦¬í•  ê²ƒì´ë‹¤.
- ìŠ¤í¬ë¡¤ ë  ë•Œ íƒ€ì´ë¨¸ê°€ fireë˜ê²Œ í•˜ê³  ì‹¶ë‹¤ë©´, íƒ€ì´ë¨¸ë¥¼ `NSRunLoopCommonModes`ì˜ ëŸ°ë£¨í‘¸ì— ë„£ì–´ì•¼ í•œë‹¤.



<br>
<br>

## Queue-based concurrency APIs
- `Grand Central Dispatch`, `NSOperationQueue`
- centrally managing a thread pool that everybody uses collaboratively. // ëª¨ë‘ê°€ í˜‘ë ¥í•´ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ìŠ¤ë ˆë“œ í’€ì„ ì¤‘ì•™ì—ì„œ ê´€ë¦¬í•´ì¤€ë‹¤.


## GCD

âœ“ GCD decides on which particular thread your code blocks are going to be executed on, and it manages these threads according to the available system resources.
- ìŠ¤ë ˆë“œ ê´€ë¦¬ëŠ” ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ì—ì„œ ì•Œì•„ì„œ ì²˜ë¦¬í•´ì¤„í…Œë‹ˆ,

âœ“ Think about work items in a queue rather than threads. 
- ìŠ¤ë ˆë“œ ë³´ë‹¤ëŠ” ì‹¤í–‰í•´ì•¼ í•  ì‘ì—… ë‹¨ìœ„ì— ê°œë°œìë“¤ì´ ì§‘ì¤‘í•  ìˆ˜ ìˆë„ë¡!


<br>


## Operation Queues

âœ“ The NSOperationQueue class has two different types of queues: the main queue and custom queues. The main queue runs on the main thread, and custom queues are processed in the background. In any case, the tasks which are processed by these queues are represented as subclasses of NSOperation.
- ë©”ì¸ í (ë©”ì¸ ìŠ¤ë ˆë“œì—ì„œ ë”)ì™€ ì»¤ìŠ¤í…€ í (ë°±ê·¸ë¼ìš´ë“œ ìŠ¤ë ˆë“œì—ì„œ ë”)ê°€ ìˆë‹¤. 

âœ“ `maxConcurrentOperationCount` property. Setting it to one gives you a serial queue, which is great for isolation purposes.
- ìµœëŒ€ë¡œ concurrent í•˜ê²Œ ëŒì•„ê°ˆ ìˆ˜ ìˆëŠ” operation countë¥¼ ì§€ì •í•  ìˆ˜ë„ ìˆë‹¤.


<br>
<br>

# ğŸ˜« ì—¬ëŸ¬ê°€ì§€ ì¢‹ì§€ ì•Šì€ ìƒí™©ë“¤ê³¼ ì†”ë£¨ì…˜ë“¤

### ì´ìœ : Sharing of Resources
- Anything you share between multiple threads is a potential point of conflict, and you have to take safety measures to prevent these kind of conflicts.
- ë©€í‹° ìŠ¤ë ˆë“œê°„ì— ê³µìœ ë˜ëŠ” ìì›ì€ ì¶©ëŒì˜ ìš”ì†Œì´ë‹¤.

## Race Conditions
## Lock
## language level support (`atomic`)
## Dead Lock
## Explosion